# Interpretability AI Reading Course

---

Please read it sequentially.

---

* https://papers.baulab.info/ 
* https://distill.pub/2017/feature-visualization/
* https://distill.pub/2017/aia/
* https://distill.pub/2018/building-blocks/
* https://distill.pub/2018/feature-wise-transformations/
* https://distill.pub/2018/differentiable-parameterizations/
* https://distill.pub/2020/attribution-baselines/
* https://distill.pub/2020/grand-tour/
* https://distill.pub/2021/multimodal-neurons/
* https://distill.pub/2019/activation-atlas/ 
* (Circuits) https://distill.pub/2020/circuits/
* https://transformer-circuits.pub/
* https://transformer-circuits.pub/2023/interpretability-dreams/index.html 
* https://www.anthropic.com/news/mapping-mind-language-model 
* https://www.anthropic.com/news/golden-gate-claude 
* Introduction to Interpretability: https://www.youtube.com/watch?v=TxhhMTOTMDg
* Podcast & Discussion: https://open.spotify.com/episode/5UF79Uu94ia0fwC32a89LU
* Interpretability Challenges: https://www.anthropic.com/research/engineering-challenges-interpretability
* Chris Olahâ€™s Blog: https://colah.github.io/about.html
* Resource from Distill Journal: https://distill.pub/ 
* https://www.neelnanda.io/mechanistic-interpretability
* https://www.alignmentforum.org/
* https://www.alignmentforum.org/w/interpretability-ml-and-ai
