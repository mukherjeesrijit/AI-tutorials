# Interpretable AI 

* [Join this WhatsApp community](https://chat.whatsapp.com/Ltny00USikU1JEuVArJHwW) for discussion & access to micro content.
* ⭐ Star this repository if you find enough value, and use it for your work.
* If you want me to add something to it, email me at support@srijitmukherjee.com.

---

## How to start?

* Start here with a vision AI tutorial.
* Then, go on to the [reading course](https://github.com/mukherjeesrijit/interpretable-ai/blob/main/reading-course.md).
* More tutorials and reading courses are coming, soon.
* Want specific to medical or domain-specific Interpretable AI? Email me.
 
---

## What is the goal?

This repository is directed toward building tutorials, resources, research papers, and code bases in pytorch for interpretable AI methodologies. My goal is to help everyone build a non-black-box AI and fully understand and look inside the model, one is creating. AI is an artificial brain, that we are striving towards. We don't understand our own brain, but at least we should strive to build the brain, we are building with our own hands, right?

## Why does Interpretable AI matter?

Humans operate in low-dimensional space. Machines operate in high-dimensional space. Humans can adapt to high-dimensional thinking. This is where abstraction becomes essential. Understanding machines is crucial. Not because they will take over, but because they outperform us in many tasks. The problem? We don’t understand why. To evolve, we must bridge this gap. We need to understand how machines think. Machines operate in abstract spaces, without self-awareness or intent. Humans must learn to interpret them. Train their minds. Use AI effectively. Not as a replacement, but as a tool. This is how we push humanity forward.
